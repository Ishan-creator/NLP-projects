{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi its me \n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "doc = nlp(\"hi its me \")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"hello world!!!\")\n",
    "\n",
    "token = 0\n",
    "for word in doc:\n",
    "    token += 1\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calling the nlp from the spacy it tokenizes the text before displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4]\n",
      "Text:  ['It', 'costs', '$', '5', '.']\n",
      "is_alpha:  [True, True, False, False, False]\n",
      "is_punct: [False, False, False, False, True]\n",
      "like_num: [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"It costs $5.\")\n",
    "\n",
    "#lexical attributes: i, text\n",
    "print(\"Index: \", [token.i for token in doc])\n",
    "print(\"Text: \", [token.text for token in doc])\n",
    "\n",
    "#lexical attributes: is_alpha, is_punct, like_num\n",
    "print(\"is_alpha: \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:\", [token.is_punct for token in doc])\n",
    "print(\"like_num:\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "nlp = English()\n",
    "\n",
    "doc = nlp(\n",
    "        \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        next = doc[token.i+1]\n",
    "        # print(next.text)\n",
    "        if next.text == \"%\":\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON am\n",
      "am AUX am\n",
      "the DET boi\n",
      "good ADJ boi\n",
      "boi NOUN am\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I am the good boi\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_ , token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India GPE\n",
      "Nepal GPE\n",
      "1 Million CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"India and Nepal traded 1 Million\")\n",
    "\n",
    "for token in doc.ents:\n",
    "    print( token.text,token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the matcher from spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "\n",
    "def match_patterns(pattern_id, pattern, some_text):\n",
    "    \"\"\"\n",
    "    matches pattern passed as argument to the text given\n",
    "    \n",
    "    Arguments:\n",
    "    pattern_id: Unique pattern identifier\n",
    "    pattern: desired pattern\n",
    "    some_text: text from where matche pattern to be extracted\n",
    "    \n",
    "    Returns:\n",
    "    matches: list of tuples of matched pattern\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    matcher.add(pattern_id, [pattern])\n",
    "\n",
    "    doc = nlp(some_text)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        matched_span = doc[start:end]\n",
    "        print(\"matched patterns:\", matched_span)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched patterns: downloaded Fortnite\n",
      "matched patterns: downloading Minecraft\n",
      "matched patterns: download Winzip\n"
     ]
    }
   ],
   "source": [
    "pattern_id = \"DOWNLOAD_THINGS_PATTERN\"\n",
    "\n",
    "#define pattern\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"download\"},\n",
    "    {\"POS\": \"PROPN\"}\n",
    "]\n",
    "\n",
    "#some text\n",
    "some_text = \"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\"\n",
    "\n",
    "#call previously defined function\n",
    "matches = match_patterns(pattern_id, pattern, some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
